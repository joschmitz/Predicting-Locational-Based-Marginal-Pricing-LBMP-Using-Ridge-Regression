{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165b7eea-6d78-41bb-a2c9-2295d18297ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d700ed52-0283-4374-b48b-9e82d3c1f248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\jolen\\NAPES-Home\\Verify\\Other\\FinalFinal\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de90dee-ffb1-49b6-8998-22ba15e37f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time Stamp', 'Name', 'PTID', 'LBMP', 'Marginal Cost Losses',\n",
       "       'Marginal Cost Congestion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming all your CSV files are in the same directory\n",
    "# Use glob to get all CSV files\n",
    "all_files = glob.glob(\"ISO/*.csv\")\n",
    "\n",
    "# Read and merge all CSV files\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Modify column names to remove \"($/MWHr)\" and any trailing spaces\n",
    "merged_df.columns = merged_df.columns.str.replace(r\"\\(\\$/MWHr\\)\", \"\", regex=True).str.strip()\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "merged_df.to_csv(\"Day_ahead_data.csv\", index=False)\n",
    "\n",
    "merged_df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2fff73-4f47-4698-b631-23c5bad6fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for PTID 61757 saved to 61757_Day_Ahead.csv\n",
      "Data for PTID 61754 saved to 61754_Day_Ahead.csv\n",
      "Data for PTID 61760 saved to 61760_Day_Ahead.csv\n",
      "Data for PTID 61753 saved to 61753_Day_Ahead.csv\n",
      "Data for PTID 61844 saved to 61844_Day_Ahead.csv\n",
      "Data for PTID 61758 saved to 61758_Day_Ahead.csv\n",
      "Data for PTID 61762 saved to 61762_Day_Ahead.csv\n",
      "Data for PTID 61756 saved to 61756_Day_Ahead.csv\n",
      "Data for PTID 61759 saved to 61759_Day_Ahead.csv\n",
      "Data for PTID 61761 saved to 61761_Day_Ahead.csv\n",
      "Data for PTID 61755 saved to 61755_Day_Ahead.csv\n",
      "Data for PTID 61845 saved to 61845_Day_Ahead.csv\n",
      "Data for PTID 61846 saved to 61846_Day_Ahead.csv\n",
      "Data for PTID 61847 saved to 61847_Day_Ahead.csv\n",
      "Data for PTID 61752 saved to 61752_Day_Ahead.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming your dataset is loaded into a DataFrame named df\n",
    "# Load the data\n",
    "df = pd.read_csv('Day_ahead_data.csv')\n",
    "\n",
    "# Iterate over each unique 'PTID' value\n",
    "for ptid in merged_df['PTID'].unique():\n",
    "    # Filter the DataFrame for the current 'PTID'\n",
    "    filtered_df = merged_df[merged_df['PTID'] == ptid]\n",
    "    \n",
    "    # Generate the filename for the current 'PTID'\n",
    "    filename = f\"{ptid}_Day_Ahead.csv\"\n",
    "    \n",
    "    # Save the filtered DataFrame to a separate file\n",
    "    filtered_df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"Data for PTID {ptid} saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920b8c88-950e-47ad-94d5-71061088e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time Stamp', 'Name', 'PTID', 'LBMP', 'Marginal Cost Losses',\n",
       "       'Marginal Cost Congestion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the CSV file\n",
    "df = pd.read_csv(\"61761_Day_Ahead.csv\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fa03de7-6b37-4df9-b9f6-6d07f6584a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly statistics with actuals saved to 61761_Day_Ahead.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"61761_Day_Ahead.csv\")\n",
    "\n",
    "# Ensure the 'Time Stamp' column is datetime\n",
    "df['Time Stamp'] = pd.to_datetime(df['Time Stamp'])\n",
    "\n",
    "# Extract Year, Month, and Hour from 'Time Stamp' if not present\n",
    "if 'Year' not in df.columns:\n",
    "    df['Year'] = df['Time Stamp'].dt.year\n",
    "if 'Month' not in df.columns:\n",
    "    df['Month'] = df['Time Stamp'].dt.month\n",
    "if 'Day' not in df.columns:\n",
    "    df['Day'] = df['Time Stamp'].dt.day\n",
    "if 'Hour' not in df.columns:\n",
    "    df['Hour'] = df['Time Stamp'].dt.hour\n",
    "\n",
    "# Calculate the day number within each week (Monday=1, Sunday=7)\n",
    "df['Day_of_Week'] = df['Time Stamp'].dt.dayofweek + 1   \n",
    "\n",
    "# Create a new column 'Date' using 'Year', 'Month', and 'Day'\n",
    "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_file = '61761_Day_Ahead.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Hourly statistics with actuals saved to {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2af9c4c-0305-4c43-9791-cd1b0cfe12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly statistics with actuals saved to 61761_Day_Ahead_NoLBMP.csv\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"61761_Day_Ahead.csv\")\n",
    "\n",
    "# Ensure the 'Time Stamp' column is datetime\n",
    "df['Time Stamp'] = pd.to_datetime(df['Time Stamp'])\n",
    "\n",
    "# Extract Year, Month, Day, and Hour from 'Time Stamp' if not present\n",
    "if 'Year' not in df.columns:\n",
    "    df['Year'] = df['Time Stamp'].dt.year\n",
    "if 'Month' not in df.columns:\n",
    "    df['Month'] = df['Time Stamp'].dt.month\n",
    "if 'Day' not in df.columns:\n",
    "    df['Day'] = df['Time Stamp'].dt.day\n",
    "if 'Hour' not in df.columns:\n",
    "    df['Hour'] = df['Time Stamp'].dt.hour\n",
    "\n",
    "# Calculate the day number within each week (Monday=1, Sunday=7)\n",
    "df['Day_of_Week'] = df['Time Stamp'].dt.dayofweek + 1   \n",
    "\n",
    "# Create a new column 'Date' using 'Year', 'Month', and 'Day'\n",
    "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Remove 'LBMP' column\n",
    "df.drop(columns=['LBMP'], inplace=True)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_file = '61761_Day_Ahead_NoLBMP.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Hourly statistics with actuals saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f85b2-3603-4e87-af8a-4a28ef7d9b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395ce36-2de3-44bb-a8a7-c78de9bc1a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
